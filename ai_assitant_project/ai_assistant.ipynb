{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Web Scraping (example with “Books to Scrape”)"
      ],
      "metadata": {
        "id": "CNZAFxlvqz6-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKNi7xFjqvCG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import time\n",
        "\n",
        "def scrape_books(base_url=\"https://books.toscrape.com/\"):\n",
        "    \"\"\"\n",
        "    Extracts book data (title, price, category) from the BooksToScrape site (just 1 or 2 pages for demo).\n",
        "    Returns a list of dictionaries with the scraped information.\n",
        "    \"\"\"\n",
        "    all_books = []\n",
        "\n",
        "    # We'll scrape the first page as an example\n",
        "    page_url = base_url + \"catalogue/page-1.html\"\n",
        "    response = requests.get(page_url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error accessing {page_url}\")\n",
        "        return all_books\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    # Find all book containers\n",
        "    books = soup.select(\"article.product_pod\")\n",
        "\n",
        "    for book in books:\n",
        "        title_element = book.select_one(\"h3 a\")\n",
        "        price_element = book.select_one(\"p.price_color\")\n",
        "        # Link to the individual book page\n",
        "        book_link = title_element.get(\"href\")\n",
        "\n",
        "        title = title_element.get(\"title\", \"No Title\")\n",
        "        price = price_element.text if price_element else \"No Price\"\n",
        "\n",
        "        # For category, we'll grab data from the individual book page (optional, simplified demo)\n",
        "        # We'll make a second request:\n",
        "        full_link = base_url + \"catalogue/\" + book_link\n",
        "        book_resp = requests.get(full_link)\n",
        "        if book_resp.status_code == 200:\n",
        "            book_soup = BeautifulSoup(book_resp.text, \"html.parser\")\n",
        "            # Normally, we'd extract more info, e.g., the category from the navigation bar\n",
        "            category_element = book_soup.select(\"ul.breadcrumb li a\")\n",
        "            if category_element and len(category_element) >= 3:\n",
        "                category = category_element[2].text.strip()\n",
        "            else:\n",
        "                category = \"No Category\"\n",
        "\n",
        "            product_description_element = book_soup.select_one(\"#product_description ~ p\")\n",
        "            if product_description_element:\n",
        "                description = product_description_element.text.strip()\n",
        "            else:\n",
        "                description = \"Description not available.\"\n",
        "\n",
        "        else:\n",
        "            category = \"No Category\"\n",
        "            description = \"Description not available.\"\n",
        "\n",
        "        all_books.append({\n",
        "            \"title\": title,\n",
        "            \"price\": price,\n",
        "            \"category\": category,\n",
        "            \"description\": description\n",
        "        })\n",
        "\n",
        "        # Brief pause to avoid sending too many requests in a short time\n",
        "        time.sleep(1)\n",
        "\n",
        "    return all_books\n",
        "\n",
        "def save_data(data, filename=\"books_data.json\"):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = scrape_books()\n",
        "    print(f\"Scraped {len(data)} books.\")\n",
        "    save_data(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loading the Data and Creating the Virtual Assistant"
      ],
      "metadata": {
        "id": "GxIFNtqZqyec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def load_products(filepath=\"books_data.json\"):\n",
        "    \"\"\"\n",
        "    Loads the scraped data from a local JSON file.\n",
        "    \"\"\"\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        products = json.load(f)\n",
        "    return products\n",
        "\n",
        "def search_products(query, products):\n",
        "    \"\"\"\n",
        "    A simple search in 'title', 'category', or 'description'.\n",
        "    \"\"\"\n",
        "    query_lower = query.lower()\n",
        "    results = []\n",
        "    for p in products:\n",
        "        content = (\n",
        "            p['title'].lower() + \" \" +\n",
        "            p['category'].lower() + \" \" +\n",
        "            p['description'].lower()\n",
        "        )\n",
        "        # This line checks if any word in the query is in the content\n",
        "        if any(word in content for word in query_lower.split()):\n",
        "            results.append(p)\n",
        "    return results\n",
        "\n",
        "def query_ollama(context, question):\n",
        "    \"\"\"\n",
        "    Sends the question + context to Ollama to generate a natural-language answer.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a virtual customer service assistant. Answer in English using ONLY the following product information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "If you do not have enough information in the context, say: \"I'm sorry, I don't have that information.\"\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        resp = requests.post(\n",
        "            \"http://localhost:11411/generate\",  # Adjust if Ollama is running on a different port or address\n",
        "            json={\"prompt\": prompt}\n",
        "        )\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            return data.get(\"response\", \"\")\n",
        "        else:\n",
        "            return f\"Error {resp.status_code}: Could not contact Ollama server.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error connecting to Ollama: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    print(\"=== Virtual Assistant (BooksToScrape) ===\")\n",
        "    # 1. Load data\n",
        "    products = load_products()\n",
        "\n",
        "    # 2. Chat loop\n",
        "    while True:\n",
        "        user_question = input(\"\\nUser: \").strip()\n",
        "        if not user_question:\n",
        "            continue\n",
        "        if user_question.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Goodbye.\")\n",
        "            break\n",
        "\n",
        "        # 2a. Search relevant products\n",
        "        matches = search_products(user_question, products)\n",
        "\n",
        "        # 2b. Build a 'context' from the first 3 results\n",
        "        if matches:\n",
        "            context_text = \"\"\n",
        "            for c in matches[:3]:\n",
        "                context_text += (\n",
        "                    f\"- Title: {c['title']}\\n\"\n",
        "                    f\"  Category: {c['category']}\\n\"\n",
        "                    f\"  Price: {c['price']}\\n\"\n",
        "                    f\"  Description: {c['description'][:200]}...\\n\\n\"\n",
        "                )\n",
        "        else:\n",
        "            context_text = \"No relevant products found.\"\n",
        "\n",
        "        # 2c. Query Ollama\n",
        "        answer = query_ollama(context_text, user_question)\n",
        "\n",
        "        # 2d. Display the answer\n",
        "        print(f\"Assistant: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "NK8LDoddrGRT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}